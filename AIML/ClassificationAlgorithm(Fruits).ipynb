{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentation refers to the process of generating new training samples by applying various transformations to the existing data. This technique is particularly useful in deep learning and machine learning, as it helps increase the diversity of the training data without actually collecting new data. The goal of augmentation is to improve the model's generalization ability by introducing variations that the model may encounter in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# import wget\n",
    "import os\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, log_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple Braeburn', 'Apple Granny Smith', 'Apricot', 'Avocado', 'Banana', 'Blueberry', 'Cactus fruit', 'Cantaloupe', 'Cherry', 'Clementine', 'Corn', 'Cucumber Ripe', 'Grape Blue', 'Kiwi', 'Lemon', 'Limes', 'Mango', 'Onion White', 'Orange', 'Papaya', 'Passion Fruit', 'Peach', 'Pear', 'Pepper Green', 'Pepper Red', 'Pineapple', 'Plum', 'Pomegranate', 'Potato Red', 'Raspberry', 'Strawberry', 'Tomato', 'Watermelon']\n",
      "{'Apple Braeburn': 0, 'Apple Granny Smith': 1, 'Apricot': 2, 'Avocado': 3, 'Banana': 4, 'Blueberry': 5, 'Cactus fruit': 6, 'Cantaloupe': 7, 'Cherry': 8, 'Clementine': 9, 'Corn': 10, 'Cucumber Ripe': 11, 'Grape Blue': 12, 'Kiwi': 13, 'Lemon': 14, 'Limes': 15, 'Mango': 16, 'Onion White': 17, 'Orange': 18, 'Papaya': 19, 'Passion Fruit': 20, 'Peach': 21, 'Pear': 22, 'Pepper Green': 23, 'Pepper Red': 24, 'Pineapple': 25, 'Plum': 26, 'Pomegranate': 27, 'Potato Red': 28, 'Raspberry': 29, 'Strawberry': 30, 'Tomato': 31, 'Watermelon': 32}\n",
      "{0: 'Apple Braeburn', 1: 'Apple Granny Smith', 2: 'Apricot', 3: 'Avocado', 4: 'Banana', 5: 'Blueberry', 6: 'Cactus fruit', 7: 'Cantaloupe', 8: 'Cherry', 9: 'Clementine', 10: 'Corn', 11: 'Cucumber Ripe', 12: 'Grape Blue', 13: 'Kiwi', 14: 'Lemon', 15: 'Limes', 16: 'Mango', 17: 'Onion White', 18: 'Orange', 19: 'Papaya', 20: 'Passion Fruit', 21: 'Peach', 22: 'Pear', 23: 'Pepper Green', 24: 'Pepper Red', 25: 'Pineapple', 26: 'Plum', 27: 'Pomegranate', 28: 'Potato Red', 29: 'Raspberry', 30: 'Strawberry', 31: 'Tomato', 32: 'Watermelon'}\n"
     ]
    }
   ],
   "source": [
    "directory = \"R:/AI Ml/.ipynb_checkpoints/FruitsData/fruits/train/train\"\n",
    "Name = []\n",
    "for file in os.listdir(directory):\n",
    "    Name+=[file]\n",
    "\n",
    "# print(Name) -->  in Name all folders are stored it's represent as Fruits\n",
    "fruit_map = dict(zip(Name,[i for i in range(len(Name))]))\n",
    "# This is dictionary in which each filder ( fruit ) is listed as index of folder\n",
    "print(fruit_map)\n",
    "\n",
    "r_fruit_map = dict(zip([i for i in range(len(Name))],Name))\n",
    "print(r_fruit_map)\n",
    "# os.listdir(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the images into train, validation, test sets\n",
    "* Perform data augmentation by using ImageDataGenerator so that we can acquire more relevant data from the existing images by making minor alterations to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* rescale=1.0/255.0: This scales the pixel values of the images from the range [0, 255] to the range [0, 1]. It is a common preprocessing step in deep learning to normalize the input data.\n",
    "\n",
    "* vertical_flip=True: This allows vertical flipping of the images as part of the data augmentation process.\n",
    "\n",
    "* horizontal_flip=True: This allows horizontal flipping of the images as part of the data augmentation process.\n",
    "\n",
    "* rotation_range=40: This randomly rotates the images within the specified range of degrees (0 to 40 degrees) as part of the data augmentation process.\n",
    "\n",
    "* width_shift_range=0.2: This randomly shifts the images horizontally by a fraction of the total width (20% in this case) as part of the data augmentation process.\n",
    "\n",
    "* height_shift_range=0.2: This randomly shifts the images vertically by a fraction of the total height (20% in this case) as part of the data augmentation process.\n",
    "\n",
    "* zoom_range=0.1: This randomly zooms in and out on images by up to 10% as part of the data augmentation process.\n",
    "* validation_split=0.2: This specifies that 20% of the data will be used for validation.\n",
    "\n",
    "* target_size=(100, 100): This resizes all images to 100x100 pixels. This is the size that the neural network will process.\n",
    "\n",
    "* batch_size=32 for training and batch_size=16 for validation and testing: This is the number of images to be yielded from the generator per batch.\n",
    "\n",
    "* class_mode='categorical': This means the labels are one-hot encoded. It is used for multi-class classification.\n",
    "\n",
    "* subset='training' or subset='validation': Specifies whether the generator is used for the training or validation subset. This requires the ImageDataGenerator to have a validation_split parameter set.\n",
    "\n",
    "* shuffle=True: This means the data will be shuffled at each epoch, which is useful for training to prevent the model from seeing the same order of data at each epoch. For the test set, shuffle=False is often used to maintain the order for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This generator will read images from the specified directory, apply augmentations, and \n",
    "# yield batches of 32 images with their labels for training.\n",
    "img_data_gen = ImageDataGenerator(rescale=1./255,\n",
    "vertical_flip = True,\n",
    "horizontal_flip = True,\n",
    "rotation_range = 40,\n",
    "width_shift_range = 0.2,\n",
    "height_shift_range = 0.2,\n",
    "zoom_range = 0.1,\n",
    "validation_split = 0.2\n",
    ")\n",
    "\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16623 images belonging to 33 classes.\n",
      "Found 3314 images belonging to 33 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = test_data_gen.flow_from_directory(directory,\n",
    "shuffle = True,\n",
    "batch_size = 32,\n",
    "subset = 'training',\n",
    "target_size=(100,100))\n",
    "\n",
    "valid_generator = img_data_gen.flow_from_directory(directory,\n",
    "shuffle=True,\n",
    "batch_size=16,\n",
    "subset='validation',\n",
    "target_size=(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masking, igon vector, filters, transformation vectors these are used to divide data into layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
